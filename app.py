# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cW6b6iVHDAwASVA-Ne-4x5gZKuZfwtEB
"""
from flask_cors import CORS
from flask import Flask, jsonify, make_response, request

app = Flask(__name__)
CORS(app)
# run_with_ngrok(app) 

from scipy.sparse import hstack
import nltk
nltk.download('punkt')
from nltk.corpus import stopwords
nltk.download('stopwords')
", ".join(stopwords.words('english'))

STOPWORDS = set(stopwords.words('english'))
def remove_stopwords(text):
    return " ".join([word for word in str(text).split() if word not in STOPWORDS])

import pickle
scikit_log_reg=pickle.load(open('model.pkl','rb'))
word_tokenize=pickle.load(open('tokenize.pkl','rb'))
word_vectorizer=pickle.load(open('word_vectorizer.pkl','rb'))
char_vectorizer=pickle.load(open('char_vectorizer.pkl','rb'))

@app.route("/")
def putStatus():
    return "Status: Running and Active..."

@app.route('/predict',methods=['POST'])
def getPredictions():
  data = request.get_json(force=True)
  sentence = str(data['Sentence'])
  sentence = remove_stopwords(sentence)
  tokenized_input = word_tokenize(sentence)
  tfidf_test_vec = word_vectorizer.transform([tokenized_input])

  char_test_vec = char_vectorizer.transform([tokenized_input])
  final_ip = hstack([tfidf_test_vec, char_test_vec])
  input_formmated = scikit_log_reg.predict(final_ip)

  if input_formmated==0 :
    return 'Sentence is Positive'
  else :
    return 'Sentence is Negative'
#app.run()
if __name__ == '__main__':
    app.run(debug=False if os.environ.get("PORT") else True, port= int(os.environ.get("PORT") or 8080))#5000)